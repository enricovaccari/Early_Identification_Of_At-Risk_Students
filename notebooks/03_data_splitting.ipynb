{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002a9893",
   "metadata": {},
   "source": [
    "<img src=\"../extra/images/Beyond_Grades_Banner_01.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39de21",
   "metadata": {},
   "source": [
    "# ðŸ“š Project Index\n",
    "\n",
    "- [1 - IMPORTS](#1---imports)\n",
    "- [2 - DATASET LOAD](#2---dataset-load)\n",
    "- [3 - DATA SPLIT](#3---data-split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebb1ea",
   "metadata": {},
   "source": [
    "---\n",
    "># 1 - IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d91a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning.py functions module imported from: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\src\\data\n",
      "preprocessing.py functions module imported from: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\src\\data\n",
      "splitting.py functions module imported from: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\src\\data\n",
      "analysis.py functions module imported from: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\src\\features\n",
      "utils.py functions module imported from: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\src\\utilities\n",
      "Imports ready: pd, np, sns, plt, train_test_split, etc.\n",
      "PROJECT_ROOT: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\n"
     ]
    }
   ],
   "source": [
    "# Centralized setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure PROJECT_PATH is in sys\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "PROJECT_PATH = PROJECT_ROOT / \"src\" / \"project\"\n",
    "\n",
    "if str(PROJECT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_PATH))\n",
    "\n",
    "# Centralized import\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474e353",
   "metadata": {},
   "source": [
    "---\n",
    "># 2 - DATASET LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0590af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/interim/dataset_structural_cleanup.xlsx\"\n",
    "try:\n",
    "    df = utils.load_student_dataset(dataset_path)\n",
    "    print('Data loaded successfully.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred during data loading: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f874b7",
   "metadata": {},
   "source": [
    "---\n",
    "># 3 - DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3123f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratification by quantiles: q=5\n",
      "\n",
      "Training target distribution (same edges as stratify):\n",
      "GPA\n",
      "0    383\n",
      "1    383\n",
      "2    382\n",
      "3    382\n",
      "4    383\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test target distribution (same edges as stratify):\n",
      "GPA\n",
      "0    96\n",
      "1    95\n",
      "2    96\n",
      "3    96\n",
      "4    96\n",
      "Name: count, dtype: int64\n",
      "âœ… File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_X_train_aftersplit.xlsx\n",
      "âœ… File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_X_test_aftersplit.xlsx\n",
      "âœ… File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_y_train_aftersplit.xlsx\n",
      "âœ… File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_y_test_aftersplit.xlsx\n",
      "\n",
      "Split completed and files saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Define features/target\n",
    "X = df.drop(columns=[\"GPA\"])\n",
    "y = df[\"GPA\"]\n",
    "\n",
    "# 2) Split with safe stratification\n",
    "X_train, X_test, y_train, y_test, meta = splitting.safe_train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, max_q=5, verbose=True\n",
    ")\n",
    "\n",
    "# 3) Check distributions using the SAME bin edges used for stratification\n",
    "if meta[\"bin_edges\"] is not None:\n",
    "    edges = meta[\"bin_edges\"]\n",
    "    print(\"\\nTraining target distribution (same edges as stratify):\")\n",
    "    print(pd.cut(y_train, bins=edges, labels=False, include_lowest=True).value_counts().sort_index())\n",
    "\n",
    "    print(\"\\nTest target distribution (same edges as stratify):\")\n",
    "    print(pd.cut(y_test, bins=edges, labels=False, include_lowest=True).value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\n(No stratification used â€” skipping quantile distribution check)\")\n",
    "\n",
    "# 4) Save (Excel-friendly)\n",
    "X_train_to_save = splitting.for_excel(X_train)\n",
    "X_test_to_save  = splitting.for_excel(X_test)\n",
    "\n",
    "utils.save_dataset(X_train_to_save, \"interim/02_X_train_aftersplit.xlsx\")\n",
    "utils.save_dataset(X_test_to_save,  \"interim/02_X_test_aftersplit.xlsx\")\n",
    "utils.save_dataset(y_train.to_frame(\"GPA\"), \"interim/02_y_train_aftersplit.xlsx\")\n",
    "utils.save_dataset(y_test.to_frame(\"GPA\"),  \"interim/02_y_test_aftersplit.xlsx\")\n",
    "\n",
    "print(\"\\nSplit completed and files saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a84c32",
   "metadata": {},
   "source": [
    ">End of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bb306",
   "metadata": {},
   "source": [
    "Proper Data Splitting Implemented\n",
    "\n",
    ">- Applied appropriate splitting strategy for your data type.\n",
    ">- Maintained temporal/geographic/hierarchical integrity.\n",
    ">- Validated split quality and representativeness.\n",
    ">- Documented splitting approach for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
