{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c37efe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>NOTEBOOK 3 - Data Splitting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebb1ea",
   "metadata": {},
   "source": [
    "---\n",
    "># 1 - IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcecc1",
   "metadata": {},
   "source": [
    "### 1.1 - SETUP PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d91a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# Standard libraries\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import json  # for saving split metadata\n",
    "\n",
    "# Third-party\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add \"../src/utilities\" to sys.path for custom utilities\n",
    "sys.path.append(\"../src/utilities\")  # Ensure src/ is in path\n",
    "\n",
    "# Import utils (reload to pick up latest edits)\n",
    "try:\n",
    "    import utils\n",
    "    importlib.reload(utils)   # Ensures latest version is loaded\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Could not import utils module: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474e353",
   "metadata": {},
   "source": [
    "---\n",
    "># 2 - DATASET LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9bab1",
   "metadata": {},
   "source": [
    "### 2.1 - LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a0590af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_pickle(\"../data/interim/02_dataset_structural_cleanup.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f874b7",
   "metadata": {},
   "source": [
    "---\n",
    "># 3 - DATA SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8c866",
   "metadata": {},
   "source": [
    "### 3.1 - SPLITTING WITH STRATIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd714b2",
   "metadata": {},
   "source": [
    "In this step, the dataset is divided into two groups: a **training set** and a **test set**.\n",
    "\n",
    "- The **training set** (80%) is used for Exploratory Data Analysis (EDA) and model development.  \n",
    "- The **test set** (20%) remains unseen during training. It is transformed using preprocessing parameters fitted on the training data and serves as a final benchmark for model evaluation.  \n",
    "\n",
    "The following dataframes are created:\n",
    "- `X_train`: features for training  \n",
    "- `X_test`: features for testing  \n",
    "- `y_train`: target values for training  \n",
    "- `y_test`: target values for testing  \n",
    "\n",
    "**Method**  \n",
    "- **Target**: `target` (the label to be predicted)  \n",
    "- **Stratification**: performed on `y` to maintain proportional class distributions across splits  \n",
    "- **Function**: `train_test_split` (from `sklearn.model_selection`)  \n",
    "- **Test size**: 0.20 (20% of the data)  \n",
    "- **Random seed**: 42 (ensures reproducibility)  \n",
    "- **Leakage prevention**: splitting is done **before** any preprocessing or feature engineering  \n",
    "\n",
    "---\n",
    "**Checks performed**  \n",
    "- Verified that **train/test sizes** match the expected proportions  \n",
    "- Confirmed **class distribution consistency** between train and test sets  \n",
    "- Ensured **no overlap** of indices between partitions  \n",
    "\n",
    "\n",
    "**Artifacts saved**  \n",
    "- Train and test **dataframes** (Excel-friendly format for inspection)  \n",
    "- Exported splits:  \n",
    "  - `03_X_train_aftersplit.xlsx`  \n",
    "  - `03_X_test_aftersplit.xlsx`  \n",
    "  - `03_y_train_aftersplit.xlsx`  \n",
    "  - `03_y_test_aftersplit.xlsx`  \n",
    "\n",
    "**Reproducibility**  \n",
    "The split can be reproduced exactly by using the same random seed and stratification. If dataset order changes in future versions, the saved splits provide stable references for downstream work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3123f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes → X_train (3477, 30) | X_test (870, 30)\n",
      "\n",
      "Train distribution (%)\n",
      "target\n",
      "Graduate    50.82\n",
      "Dropout     30.92\n",
      "Enrolled    18.26\n",
      "\n",
      "Test distribution (%)\n",
      "target\n",
      "Graduate    50.80\n",
      "Dropout     30.92\n",
      "Enrolled    18.28\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Classification\\Early_Identification_Of_At-Risk_Students\\data\\interim\\03_X_train_aftersplit.xlsx\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Classification\\Early_Identification_Of_At-Risk_Students\\data\\interim\\03_X_test_aftersplit.xlsx\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Classification\\Early_Identification_Of_At-Risk_Students\\data\\interim\\03_y_train_aftersplit.xlsx\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Classification\\Early_Identification_Of_At-Risk_Students\\data\\interim\\03_y_test_aftersplit.xlsx\n"
     ]
    }
   ],
   "source": [
    "# DATA SPLITTING\n",
    "\n",
    "# Define features/target\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Stratified split (20% test for a slightly larger training set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.20,       # 20% test set\n",
    "    stratify=y,           # preserve class proportions\n",
    "    random_state=42       # reproducible split\n",
    ")\n",
    "\n",
    "print(f\"Shapes → X_train {X_train.shape} | X_test {X_test.shape}\")\n",
    "\n",
    "# Quick class distribution check\n",
    "print(\"\\nTrain distribution (%)\")\n",
    "print((y_train.value_counts(normalize=True) * 100).round(2).to_string())\n",
    "\n",
    "print(\"\\nTest distribution (%)\")\n",
    "print((y_test.value_counts(normalize=True) * 100).round(2).to_string())\n",
    "\n",
    "# Save to Excel-friendly format.\n",
    "def for_excel(df_like):\n",
    "    \"\"\"Return a copy safe to save to Excel (no index).\"\"\"\n",
    "    if isinstance(df_like, pd.Series):\n",
    "        return df_like.to_frame(name=df_like.name or \"target\").reset_index(drop=True)\n",
    "    return df_like.reset_index(drop=True)\n",
    "\n",
    "X_train_xl = for_excel(X_train)\n",
    "X_test_xl  = for_excel(X_test)\n",
    "y_train_xl = for_excel(y_train.rename(\"target\"))\n",
    "y_test_xl  = for_excel(y_test.rename(\"target\"))\n",
    "\n",
    "# Save as Excel files\n",
    "utils.save_dataset(X_train_xl, \"interim/03_X_train_aftersplit.xlsx\")\n",
    "utils.save_dataset(X_test_xl,  \"interim/03_X_test_aftersplit.xlsx\")\n",
    "utils.save_dataset(y_train_xl, \"interim/03_y_train_aftersplit.xlsx\")\n",
    "utils.save_dataset(y_test_xl,  \"interim/03_y_test_aftersplit.xlsx\")\n",
    "\n",
    "# Save X train and test sets as pickle files\n",
    "X_train.to_pickle(\"../data/interim/03_X_train_aftersplit.pkl\")\n",
    "X_test.to_pickle(\"../data/interim/03_X_test_aftersplit.pkl\")\n",
    "\n",
    "# Save y train and test sets as pickle files and convert to DataFrame to maintain consistency when loading later\n",
    "y_train.to_frame(name=\"target\").to_pickle(\"../data/interim/03_y_train_aftersplit.pkl\")\n",
    "y_test.to_frame(name=\"target\").to_pickle(\"../data/interim/03_y_test_aftersplit.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6678b",
   "metadata": {},
   "source": [
    "### 3.2 - SAVING SPLIT METADATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f145c",
   "metadata": {},
   "source": [
    "Below I have saved the split metadata to file (.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1872d1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved split metadata → ../data/meta/split_meta.json\n"
     ]
    }
   ],
   "source": [
    "# SAVE SPLIT METADATA\n",
    "\n",
    "split_meta = {\n",
    "    \"method\": \"train_test_split\",\n",
    "    \"params\": {\n",
    "        \"test_size\": 0.20,\n",
    "        \"random_state\": 42,\n",
    "        \"stratify\": True,  # stratification used\n",
    "    },\n",
    "    \"index\": {\n",
    "        \"train\": X_train.index.tolist(),\n",
    "        \"test\":  X_test.index.tolist(),\n",
    "    },\n",
    "    \"n_rows\": {\n",
    "        \"train\": int(len(X_train)),\n",
    "        \"test\":  int(len(X_test)),\n",
    "        \"total\": int(len(X_train) + len(X_test)),\n",
    "    },\n",
    "    \"target\": \"target\",  # classification label\n",
    "}\n",
    "\n",
    "# Ensure JSON-safe (convert any numpy/Index objects if needed)\n",
    "try:\n",
    "    safe_meta = utils.make_json_safe(split_meta)\n",
    "except NameError:\n",
    "    # fallback: cast index lists already done, so safe enough\n",
    "    safe_meta = split_meta\n",
    "\n",
    "# Save to file \n",
    "out = Path(\"../data/meta\")\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "with open(out / \"split_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(safe_meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved split metadata → ../data/meta/split_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bb306",
   "metadata": {},
   "source": [
    "Proper Data Splitting Implemented:\n",
    "\n",
    ">- Applied appropriate splitting strategy for my data type.\n",
    ">- Maintained (temporal/geographic/hierarchical) integrity.\n",
    ">- Validated split quality and representativeness.\n",
    ">- Documented splitting approach for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf50936",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Next Notebook - EDA\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
